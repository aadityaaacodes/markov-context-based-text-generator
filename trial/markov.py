from feeder import filter_text, tokeniser, array_maker
import numpy as np
import pandas as pd
import random

# receive sentence
prompt = "he jumped over the fence"
tokeniser(arr=array_maker(txt=filter_text(txt=prompt)))

# tokenise and append sentence to prob map

# make word using highest prob




# make word

# append word and prev word to prob map

# 


